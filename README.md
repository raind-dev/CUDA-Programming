# ğŸš€ CUDA Programming Examples & Practice

This repository collects my personal hands-on experiments and implementations related to **GPU programming** using:

- **C/C++ with CUDA**
- **Python with Numba**

The goal is to deepen understanding of parallel computing, GPU acceleration techniques, and real-world applications.

---

## ğŸ“ Directory Structure

```bash
cuda-programming/
â”‚
â”œâ”€â”€ cpp_cuda/                 # C/C++ with CUDA
â”‚   â”œâ”€â”€                       # 
â”‚   â”œâ”€â”€                       # 
â”‚   â”œâ”€â”€                       # 
â”‚   â””â”€â”€                       # 
â”‚
â”œâ”€â”€ python_numba/            # Python with Numba
â”‚   â”œâ”€â”€                      # 
â”‚   â”œâ”€â”€                      # 
â”‚   â”œâ”€â”€                      # 
â”‚   â””â”€â”€                      # 

ğŸ“Œ Goals
Practice low-level CUDA C/C++ kernel programming

Explore GPU acceleration in Python via Numba

Compare CPU vs GPU performance on various tasks

Serve as a foundation for future deep learning, graphics, or simulation projects

ğŸ”§ Requirements
C/C++ CUDA
NVIDIA GPU with CUDA Compute Capability

CUDA Toolkit (tested on CUDA 12.x)

CMake / gcc / nvcc

Python Numba
Python 3.8+

numba, numpy, matplotlib (optional for visualization)

Install dependencies:

bash
Copy
Edit
pip install -r requirements.txt
ğŸ’¡ Coming Up
More optimization patterns (shared memory, streams, pinned memory)

Real-time image processing examples

Integration with OpenCV and PyTorch (planned)

ğŸ“¬ Contact
If you're working on similar topics or want to collaborate, feel free to reach out via GitHub Issues.

